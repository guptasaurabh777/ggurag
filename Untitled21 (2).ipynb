{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## RAG SETUP - NyayaSarthi"
      ],
      "metadata": {
        "id": "AoKiLKcI3QoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Libraries"
      ],
      "metadata": {
        "id": "UNmZ5fHr3ZYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community langchain-openai faiss-cpu tiktoken pypdf ragas sentence_transformers"
      ],
      "metadata": {
        "id": "dK09olZm3PIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Required Packages"
      ],
      "metadata": {
        "id": "o-EtVf4J3h-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from ragas.metrics import LLMContextRecall\n",
        "from ragas import EvaluationDataset\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.metrics import LLMContextRecall\n",
        "from ragas.metrics import LLMContextPrecisionWithoutReference\n",
        "from ragas.metrics import ResponseRelevancy\n",
        "from ragas.metrics import Faithfulness\n",
        "from ragas import evaluate\n",
        "import os"
      ],
      "metadata": {
        "id": "dbVDlBKe3mHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Azure Opneai Keys & Endpoint"
      ],
      "metadata": {
        "id": "YrltUzDL4Ef7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"\""
      ],
      "metadata": {
        "id": "0Pc2zmxj4Iq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup LLM with required parameters like temperature , top_p, max_tokens etc"
      ],
      "metadata": {
        "id": "-ViWZlEV4Ln0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = AzureChatOpenAI(\n",
        "    openai_api_version=\"2025-01-01-preview\",\n",
        "    azure_deployment=\"gpt-4.1-mini\",  # Replace with your deployment name\n",
        "    temperature=0.1,\n",
        "    top_p=1,\n",
        "    max_tokens=2000)"
      ],
      "metadata": {
        "id": "DvbQZ4k74QLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant\",\n",
        "    ),\n",
        "    (\"human\", \"what is capital of india?\"),\n",
        "]\n",
        "llm.invoke(messages)"
      ],
      "metadata": {
        "id": "NTF0iGWd4TzN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}